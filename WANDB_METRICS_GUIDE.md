# WandB Logging Metrics Guide

## ğŸ“Š ì¶”ê°€ëœ í•™ìŠµ ê±´ê°•ë„ ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­

### 1. Hyperparameters (Sweep ì¶”ì ìš©)
```
wandb.config:
  - learning_rate
  - weight_decay
  - batch_size
  - pseudo_dataset_len
  - epochs
  - window_len
  - num_params
  - num_train_trials
```

### 2. ì´ˆê¸° ë°ì´í„° í†µê³„ (Baseline)
```
data_stats/normalized_mean
data_stats/normalized_std
data_stats/normalized_min
data_stats/normalized_max
data_stats/{channel_name}_mean
data_stats/{channel_name}_std
```
**ëª©ì **: ì •ê·œí™”ëœ ë°ì´í„°ì˜ ë¶„í¬ í™•ì¸

---

## ğŸ” ë§¤ Epoch ë¡œê¹… ë©”íŠ¸ë¦­

### 3. Gradient Health (í•™ìŠµ ì•ˆì •ì„±)
```
train/grad_norm_mean      # í‰ê·  gradient norm
train/grad_norm_std       # Gradient ë¶„ì‚°
train/grad_norm_max       # ìµœëŒ€ gradient
train/grad_norm_min       # ìµœì†Œ gradient
```

**ê±´ê°•í•œ í•™ìŠµ ì‹ í˜¸**:
- `grad_norm_mean`: 0.01 ~ 10 ë²”ìœ„ (ë„ˆë¬´ í¬ë©´ exploding, ë„ˆë¬´ ì‘ìœ¼ë©´ vanishing)
- `grad_norm_std`: ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ (ê¸‰ê²©í•œ ë³€í™” = ë¶ˆì•ˆì •)

**ê²½ê³  ì‹ í˜¸**:
- âš ï¸ grad_norm > 100: Exploding gradients
- âš ï¸ grad_norm < 0.001: Vanishing gradients
- âš ï¸ grad_norm_std ê¸‰ì¦: ë¶ˆì•ˆì •í•œ í•™ìŠµ

---

### 4. Batch Loss Statistics (Mode Collapse ê°ì§€)
```
train/batch_loss_mean     # ë°°ì¹˜ë³„ loss í‰ê· 
train/batch_loss_std      # ë°°ì¹˜ë³„ loss ë¶„ì‚°
train/batch_loss_max
train/batch_loss_min
train/batch_loss_cv       # Coefficient of Variation
```

**ê±´ê°•í•œ í•™ìŠµ ì‹ í˜¸**:
- `batch_loss_std` > 0: ë°°ì¹˜ë§ˆë‹¤ ë‹¤ì–‘í•œ loss (ì •ìƒ)
- `batch_loss_cv` > 0.05: ì ë‹¹í•œ ë¶„ì‚°

**ê²½ê³  ì‹ í˜¸ (Mode Collapse)**:
- âš ï¸ batch_loss_std < 0.01: ëª¨ë“  ë°°ì¹˜ê°€ ë¹„ìŠ·í•œ loss â†’ ëª¨ë¸ì´ ê°™ì€ ê²ƒë§Œ ìƒì„±
- âš ï¸ batch_loss_cv < 0.01: ë¶„ì‚° ë„ˆë¬´ ì‘ìŒ

---

### 5. Model Weight Statistics (Dead Neurons / Exploding Weights)
```
model/weight_mean         # í‰ê·  weight í¬ê¸°
model/weight_std          # Weight ë¶„ì‚°
model/weight_max          # ìµœëŒ€ weight
```

**ê±´ê°•í•œ í•™ìŠµ ì‹ í˜¸**:
- ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ë˜ê±°ë‚˜ ì²œì²œíˆ ì¦ê°€
- weight_mean: 0.01 ~ 1 ì •ë„

**ê²½ê³  ì‹ í˜¸**:
- âš ï¸ weight_max > 10: Exploding weights
- âš ï¸ weight_mean < 0.001: Dead neurons ê°€ëŠ¥ì„±
- âš ï¸ ê¸‰ê²©í•œ ë³€í™”: ë¶ˆì•ˆì •

---

### 6. EMA Model Tracking
```
model/ema_diff            # EMA ëª¨ë¸ê³¼ í˜„ì¬ ëª¨ë¸ì˜ ì°¨ì´
```

**ê±´ê°•í•œ í•™ìŠµ ì‹ í˜¸**:
- ì ì§„ì ìœ¼ë¡œ ê°ì†Œí•˜ê±°ë‚˜ ì•ˆì •ì  ìœ ì§€
- ema_diff: 0.001 ~ 0.1

**ê²½ê³  ì‹ í˜¸**:
- âš ï¸ ema_diff ê¸‰ì¦: ëª¨ë¸ì´ ë„ˆë¬´ ë¹ ë¥´ê²Œ ë³€í™”
- âš ï¸ ema_diff > 1: í•™ìŠµ ë¶ˆì•ˆì •

---

### 7. Loss Improvement Tracking
```
train/loss_decrease       # ì´ì „ epoch ëŒ€ë¹„ loss ê°ì†ŒëŸ‰
train/loss_decrease_pct   # ê°ì†Œ í¼ì„¼íŠ¸
train/is_improving        # 1=ê°œì„ ì¤‘, 0=ì •ì²´/ì•…í™”
```

**ê±´ê°•í•œ í•™ìŠµ ì‹ í˜¸**:
- loss_decrease > 0 (ê³„ì† ê°ì†Œ)
- loss_decrease_pct: ì´ˆë°˜ 5-10%, í›„ë°˜ 0.1-1%

**ê²½ê³  ì‹ í˜¸**:
- âš ï¸ is_improving = 0ì´ 10+ epoch ì—°ì†: í•™ìŠµ ì •ì²´
- âš ï¸ loss_decrease < 0: Loss ì¦ê°€ (overfitting ë˜ëŠ” ë¶ˆì•ˆì •)

---

### 8. Loss Component Ratios
```
loss_ratio/simple
loss_ratio/vel
loss_ratio/fk
loss_ratio/drift
loss_ratio/slide
```

**ëª©ì **: ì–´ë–¤ loss termì´ ì§€ë°°ì ì¸ì§€ í™•ì¸

**ê±´ê°•í•œ í•™ìŠµ**:
- ë¹„ìœ¨ì´ í¬ê²Œ ë³€í•˜ì§€ ì•Šê³  ì•ˆì •ì 

**ë¬¸ì œ ì‹ í˜¸**:
- âš ï¸ í•œ termì´ 0.9+ ì°¨ì§€: ë‹¤ë¥¸ í•­ë“¤ì´ ë¬´ì‹œë¨

---

## â­ ê°€ì¥ ì¤‘ìš”: Validation Sample Quality (50 epochë§ˆë‹¤)

### 9. Generated Sample Statistics
```
validation/gen_std        # ìƒì„±ëœ ìƒ˜í”Œ ì „ì²´ std
validation/gen_mean
validation/gen_range
```

**ê±´ê°•í•œ ìƒì„±**:
- gen_std > 0.5 (ì •ê·œí™”ëœ ê°’ ê¸°ì¤€)
- gen_range > 2.0

**Mode Collapse ê²½ê³ **:
- âš ï¸ gen_std < 0.1: ê±°ì˜ ìƒìˆ˜ ìƒì„±
- âš ï¸ gen_range < 0.5: ë‹¤ì–‘ì„± ì—†ìŒ

---

### 10. Knee Angle Quality Check
```
validation/knee_r_std     # Knee angle í‘œì¤€í¸ì°¨ (radians)
validation/knee_r_mean
validation/knee_healthy   # 1=ì •ìƒ, 0=ë¹„ì •ìƒ
```

**ê±´ê°•í•œ ìƒì„±**:
- knee_r_std > 0.1 rad (~5.7Â°)
- knee_healthy = 1

**Mode Collapse í™•ì •**:
- âš ï¸ knee_r_std < 0.05 rad (~3Â°): ê±°ì˜ ìƒìˆ˜
- âš ï¸ knee_healthy = 0: ë¹„ì •ìƒ ìƒì„±

**ì •ìƒ ë³´í–‰ ê¸°ì¤€**: Knee ROM 60-70Â°, std ~20-30Â° (0.35-0.52 rad)

---

### 11. GRF (Ground Reaction Force) Quality Check
```
validation/grf_vz_r_std   # GRF í‘œì¤€í¸ì°¨ (Newtons)
validation/grf_vz_r_mean
validation/grf_healthy    # 1=ì •ìƒ, 0=ë¹„ì •ìƒ
```

**ê±´ê°•í•œ ìƒì„±**:
- grf_vz_r_std > 10 N
- grf_healthy = 1

**Mode Collapse í™•ì •**:
- âš ï¸ grf_vz_r_std < 1 N: ê±°ì˜ ìƒìˆ˜
- âš ï¸ grf_healthy = 0: ë¹„ì •ìƒ ìƒì„±

**ì •ìƒ ë³´í–‰ ê¸°ì¤€**: GRF std ~100-300 N

---

## ğŸš¨ Mode Collapse ì¡°ê¸° ê°ì§€ ì²´í¬ë¦¬ìŠ¤íŠ¸

ë‹¤ìŒ ì¡°ê±´ ì¤‘ **3ê°œ ì´ìƒ** í•´ë‹¹í•˜ë©´ Mode Collapse:

1. âš ï¸ `batch_loss_cv < 0.01` (ë°°ì¹˜ loss ë¶„ì‚° ë„ˆë¬´ ì‘ìŒ)
2. âš ï¸ `validation/knee_healthy = 0` (ë¬´ë¦ ê°ë„ ë¹„ì •ìƒ)
3. âš ï¸ `validation/grf_healthy = 0` (GRF ë¹„ì •ìƒ)
4. âš ï¸ `validation/gen_std < 0.1` (ìƒì„± ìƒ˜í”Œ ë¶„ì‚° ë„ˆë¬´ ì‘ìŒ)
5. âš ï¸ `train/is_improving = 0` ì—°ì† 20+ epochs (í•™ìŠµ ì •ì²´)
6. âš ï¸ `grad_norm_std / grad_norm_mean < 0.1` (gradient ë‹¤ì–‘ì„± ì—†ìŒ)

---

## ğŸ“ˆ í•™ìŠµ ë‹¨ê³„ë³„ ê¸°ëŒ€ íŒ¨í„´

### Phase 1: ì´ˆê¸° í•™ìŠµ (Epoch 1-50)
- `train/total_loss`: ê¸‰ê²©íˆ ê°ì†Œ (ì˜ˆ: 1.0 â†’ 0.3)
- `grad_norm_mean`: í¬ì§€ë§Œ ì•ˆì •ì  (1-10)
- `validation/gen_std`: ì ì§„ì  ì¦ê°€ (0.3 â†’ 0.8)
- `train/is_improving = 1` ì§€ì†

### Phase 2: ìˆ˜ë ´ (Epoch 50-200)
- `train/total_loss`: ì²œì²œíˆ ê°ì†Œ (0.3 â†’ 0.15)
- `grad_norm_mean`: ê°ì†Œ ë° ì•ˆì •í™” (1-3)
- `validation/knee_healthy = 1` ë‹¬ì„±
- `validation/grf_healthy = 1` ë‹¬ì„±

### Phase 3: Fine-tuning (Epoch 200+)
- `train/total_loss`: ë¯¸ì„¸ ê°ì†Œ (0.15 â†’ 0.12)
- `loss_decrease_pct < 1%` ì§€ì†
- ëª¨ë“  validation ë©”íŠ¸ë¦­ ì•ˆì •ì  ìœ ì§€

---

## ğŸ¯ WandB Sweepì—ì„œ í™•ì¸í•  í•µì‹¬ ë©”íŠ¸ë¦­

### Sweep ë¹„êµ ì‹œ ìš°ì„ ìˆœìœ„:

1. **ìµœì¢… ì„±ëŠ¥**:
   - `validation/knee_healthy` (ë§ˆì§€ë§‰ ê°’ = 1)
   - `validation/grf_healthy` (ë§ˆì§€ë§‰ ê°’ = 1)
   - `train/total_loss` (ìµœì†Œê°’)

2. **í•™ìŠµ ì•ˆì •ì„±**:
   - `train/grad_norm_mean` (ì•ˆì •ì  ìœ ì§€)
   - `model/ema_diff` (ì‘ê³  ì•ˆì •ì )

3. **ìˆ˜ë ´ ì†ë„**:
   - `train/total_loss` ê³¡ì„  ê¸°ìš¸ê¸°
   - ëª‡ epochì— `validation/knee_healthy = 1` ë‹¬ì„±?

---

## ğŸ”§ ë¬¸ì œë³„ ì§„ë‹¨ ë° í•´ê²°

### ë¬¸ì œ 1: LossëŠ” ê°ì†Œí•˜ëŠ”ë° validation í’ˆì§ˆì´ ë‚˜ì¨
**ì¦ìƒ**:
- âœ“ train/total_loss ê°ì†Œ
- âœ— validation/knee_healthy = 0
- âœ— validation/grf_healthy = 0

**ì›ì¸**: Overfitting ë˜ëŠ” loss function ë¬¸ì œ
**í•´ê²°**: 
- Pseudo dataset í¬ê¸° ì¦ê°€ (10k â†’ 20k)
- Learning rate ê°ì†Œ

---

### ë¬¸ì œ 2: Lossê°€ ì•ˆ ë–¨ì–´ì§
**ì¦ìƒ**:
- âœ— train/is_improving = 0 ì—°ì†
- âœ— loss_decrease_pct < 0.1%

**ì›ì¸**: Learning rate ë„ˆë¬´ ë‚®ìŒ
**í•´ê²°**:
- Learning rate ì¦ê°€ (1e-4 â†’ 4e-4)

---

### ë¬¸ì œ 3: Gradient í­ë°œ
**ì¦ìƒ**:
- âœ— grad_norm_max > 100
- âœ— í•™ìŠµ ì¤‘ NaN ë°œìƒ

**ì›ì¸**: Learning rate ë„ˆë¬´ ë†’ìŒ
**í•´ê²°**:
- Learning rate ê°ì†Œ (4e-4 â†’ 1e-4)
- Gradient clipping ì¶”ê°€

---

### ë¬¸ì œ 4: Mode Collapse í™•ì •
**ì¦ìƒ**:
- âœ— validation/gen_std < 0.1
- âœ— batch_loss_cv < 0.01
- âœ— knee_healthy = 0, grf_healthy = 0

**ì›ì¸**: 
- Learning rate ë„ˆë¬´ ë†’ìŒ
- í•™ìŠµ ë°ì´í„° ë¶€ì¡±
- Batch size ë„ˆë¬´ ì‘ìŒ

**í•´ê²°**:
- Learning rate ë‚®ì¶”ê¸° (1e-4)
- Batch size í‚¤ìš°ê¸° (64)
- ë” ì˜¤ë˜ í•™ìŠµ (1000 epochs)

---

## ğŸ“Š WandB Dashboard ì¶”ì²œ Layout

### Panel 1: Training Health
- `train/total_loss` (line)
- `train/grad_norm_mean` (line)
- `train/is_improving` (bar)

### Panel 2: Validation Quality â­
- `validation/knee_r_std` (line) + threshold line at 0.1
- `validation/grf_vz_r_std` (line) + threshold line at 10
- `validation/knee_healthy` & `validation/grf_healthy` (bar)

### Panel 3: Mode Collapse Detection
- `batch_loss_cv` (line)
- `validation/gen_std` (line)
- `model/ema_diff` (line)

### Panel 4: Loss Components
- `loss_ratio/*` (stacked area chart)
